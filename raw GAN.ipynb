{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bef52c6-008e-4440-a35d-7a2246020c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:02<00:00, 3606950.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 146289.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01<00:00, 1280805.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 2280408.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Epoch [1/50] Batch 0/938 Loss D: 0.7455304861068726, Loss G: 0.7299652099609375\n",
      "Epoch [1/50] Batch 100/938 Loss D: 0.47361522912979126, Loss G: 0.853972852230072\n",
      "Epoch [1/50] Batch 200/938 Loss D: 0.6459413170814514, Loss G: 0.6012499332427979\n",
      "Epoch [1/50] Batch 300/938 Loss D: 0.48337578773498535, Loss G: 0.7055453062057495\n",
      "Epoch [1/50] Batch 400/938 Loss D: 0.6094355583190918, Loss G: 0.5253724455833435\n",
      "Epoch [1/50] Batch 500/938 Loss D: 0.36225876212120056, Loss G: 0.9337050318717957\n",
      "Epoch [1/50] Batch 600/938 Loss D: 0.45116013288497925, Loss G: 1.1629369258880615\n",
      "Epoch [1/50] Batch 700/938 Loss D: 0.4891432523727417, Loss G: 1.0086379051208496\n",
      "Epoch [1/50] Batch 800/938 Loss D: 0.3125303387641907, Loss G: 1.065537929534912\n",
      "Epoch [1/50] Batch 900/938 Loss D: 0.21333864331245422, Loss G: 1.8150198459625244\n",
      "Epoch [2/50] Batch 0/938 Loss D: 0.3555065989494324, Loss G: 0.7941721081733704\n",
      "Epoch [2/50] Batch 100/938 Loss D: 0.35061007738113403, Loss G: 1.2201159000396729\n",
      "Epoch [2/50] Batch 200/938 Loss D: 0.3286353647708893, Loss G: 0.985258162021637\n",
      "Epoch [2/50] Batch 300/938 Loss D: 0.18867352604866028, Loss G: 1.4802567958831787\n",
      "Epoch [2/50] Batch 400/938 Loss D: 0.4037650227546692, Loss G: 1.607295036315918\n",
      "Epoch [2/50] Batch 500/938 Loss D: 0.17712122201919556, Loss G: 1.6492656469345093\n",
      "Epoch [2/50] Batch 600/938 Loss D: 0.2832944989204407, Loss G: 1.554282546043396\n",
      "Epoch [2/50] Batch 700/938 Loss D: 0.2665480971336365, Loss G: 1.443807601928711\n",
      "Epoch [2/50] Batch 800/938 Loss D: 0.31273964047431946, Loss G: 1.1640760898590088\n",
      "Epoch [2/50] Batch 900/938 Loss D: 0.2778331935405731, Loss G: 1.3828843832015991\n",
      "Epoch [3/50] Batch 0/938 Loss D: 0.2680486738681793, Loss G: 2.358196258544922\n",
      "Epoch [3/50] Batch 100/938 Loss D: 0.19353894889354706, Loss G: 1.692444086074829\n",
      "Epoch [3/50] Batch 200/938 Loss D: 1.0909618139266968, Loss G: 7.223687648773193\n",
      "Epoch [3/50] Batch 300/938 Loss D: 0.24276605248451233, Loss G: 1.8442060947418213\n",
      "Epoch [3/50] Batch 400/938 Loss D: 0.30909931659698486, Loss G: 1.1938769817352295\n",
      "Epoch [3/50] Batch 500/938 Loss D: 0.12717537581920624, Loss G: 3.681013345718384\n",
      "Epoch [3/50] Batch 600/938 Loss D: 0.25104227662086487, Loss G: 1.9079571962356567\n",
      "Epoch [3/50] Batch 700/938 Loss D: 0.2774776220321655, Loss G: 2.2713887691497803\n",
      "Epoch [3/50] Batch 800/938 Loss D: 0.34178072214126587, Loss G: 1.4611868858337402\n",
      "Epoch [3/50] Batch 900/938 Loss D: 0.167422354221344, Loss G: 1.6935758590698242\n",
      "Epoch [4/50] Batch 0/938 Loss D: 0.34059274196624756, Loss G: 1.2594176530838013\n",
      "Epoch [4/50] Batch 100/938 Loss D: 0.27715086936950684, Loss G: 1.1108665466308594\n",
      "Epoch [4/50] Batch 200/938 Loss D: 0.4158478081226349, Loss G: 3.0585105419158936\n",
      "Epoch [4/50] Batch 300/938 Loss D: 0.2426135092973709, Loss G: 1.526809573173523\n",
      "Epoch [4/50] Batch 400/938 Loss D: 0.2593315839767456, Loss G: 1.536031723022461\n",
      "Epoch [4/50] Batch 500/938 Loss D: 0.31513097882270813, Loss G: 3.531792163848877\n",
      "Epoch [4/50] Batch 600/938 Loss D: 0.6001062989234924, Loss G: 11.391399383544922\n",
      "Epoch [4/50] Batch 700/938 Loss D: 0.13205812871456146, Loss G: 2.144456386566162\n",
      "Epoch [4/50] Batch 800/938 Loss D: 0.14765292406082153, Loss G: 1.8970654010772705\n",
      "Epoch [4/50] Batch 900/938 Loss D: 0.2605148255825043, Loss G: 3.0622963905334473\n",
      "Epoch [5/50] Batch 0/938 Loss D: 0.19355517625808716, Loss G: 2.5174622535705566\n",
      "Epoch [5/50] Batch 100/938 Loss D: 0.2523365914821625, Loss G: 0.9708684682846069\n",
      "Epoch [5/50] Batch 200/938 Loss D: 0.13734222948551178, Loss G: 2.1758241653442383\n",
      "Epoch [5/50] Batch 300/938 Loss D: 0.40737590193748474, Loss G: 0.8976923227310181\n",
      "Epoch [5/50] Batch 400/938 Loss D: 0.3825031518936157, Loss G: 1.6414282321929932\n",
      "Epoch [5/50] Batch 500/938 Loss D: 0.7756862640380859, Loss G: 0.9382327795028687\n",
      "Epoch [5/50] Batch 600/938 Loss D: 0.4961203634738922, Loss G: 4.45957088470459\n",
      "Epoch [5/50] Batch 700/938 Loss D: 0.13190945982933044, Loss G: 2.7350001335144043\n",
      "Epoch [5/50] Batch 800/938 Loss D: 0.8344871997833252, Loss G: 0.3798173666000366\n",
      "Epoch [5/50] Batch 900/938 Loss D: 0.5477774143218994, Loss G: 3.0660431385040283\n",
      "Epoch [6/50] Batch 0/938 Loss D: 0.22079585492610931, Loss G: 4.274235725402832\n",
      "Epoch [6/50] Batch 100/938 Loss D: 0.3460898995399475, Loss G: 0.9381866455078125\n",
      "Epoch [6/50] Batch 200/938 Loss D: 0.1043606847524643, Loss G: 1.8036409616470337\n",
      "Epoch [6/50] Batch 300/938 Loss D: 0.5311370491981506, Loss G: 1.9240083694458008\n",
      "Epoch [6/50] Batch 400/938 Loss D: 0.04878617078065872, Loss G: 3.980393409729004\n",
      "Epoch [6/50] Batch 500/938 Loss D: 0.12044686079025269, Loss G: 2.5331649780273438\n",
      "Epoch [6/50] Batch 600/938 Loss D: 0.4324142336845398, Loss G: 0.7523601055145264\n",
      "Epoch [6/50] Batch 700/938 Loss D: 0.45496806502342224, Loss G: 0.6361570954322815\n",
      "Epoch [6/50] Batch 800/938 Loss D: 0.12209315598011017, Loss G: 6.2117791175842285\n",
      "Epoch [6/50] Batch 900/938 Loss D: 0.5645263195037842, Loss G: 0.5721831321716309\n",
      "Epoch [7/50] Batch 0/938 Loss D: 0.3134363889694214, Loss G: 1.4484877586364746\n",
      "Epoch [7/50] Batch 100/938 Loss D: 1.756298303604126, Loss G: 0.19787515699863434\n",
      "Epoch [7/50] Batch 200/938 Loss D: 0.18513062596321106, Loss G: 1.2218716144561768\n",
      "Epoch [7/50] Batch 300/938 Loss D: 0.0613802969455719, Loss G: 2.4730567932128906\n",
      "Epoch [7/50] Batch 400/938 Loss D: 0.05607033520936966, Loss G: 2.341197967529297\n",
      "Epoch [7/50] Batch 500/938 Loss D: 0.06616954505443573, Loss G: 3.084660768508911\n",
      "Epoch [7/50] Batch 600/938 Loss D: 0.19402728974819183, Loss G: 1.1972143650054932\n",
      "Epoch [7/50] Batch 700/938 Loss D: 0.03218139708042145, Loss G: 3.044271945953369\n",
      "Epoch [7/50] Batch 800/938 Loss D: 0.20008060336112976, Loss G: 1.4915928840637207\n",
      "Epoch [7/50] Batch 900/938 Loss D: 0.32178789377212524, Loss G: 3.706627130508423\n",
      "Epoch [8/50] Batch 0/938 Loss D: 0.0716911032795906, Loss G: 2.4239284992218018\n",
      "Epoch [8/50] Batch 100/938 Loss D: 0.357290118932724, Loss G: 1.2923219203948975\n",
      "Epoch [8/50] Batch 200/938 Loss D: 0.12049274891614914, Loss G: 1.883642554283142\n",
      "Epoch [8/50] Batch 300/938 Loss D: 0.13663724064826965, Loss G: 3.06423282623291\n",
      "Epoch [8/50] Batch 400/938 Loss D: 0.19630102813243866, Loss G: 3.1749067306518555\n",
      "Epoch [8/50] Batch 500/938 Loss D: 0.13122162222862244, Loss G: 2.2344143390655518\n",
      "Epoch [8/50] Batch 600/938 Loss D: 0.12334879487752914, Loss G: 1.6717815399169922\n",
      "Epoch [8/50] Batch 700/938 Loss D: 0.179886132478714, Loss G: 2.0262796878814697\n",
      "Epoch [8/50] Batch 800/938 Loss D: 0.8776809573173523, Loss G: 10.090490341186523\n",
      "Epoch [8/50] Batch 900/938 Loss D: 0.20384864509105682, Loss G: 3.0069923400878906\n",
      "Epoch [9/50] Batch 0/938 Loss D: 0.2018260508775711, Loss G: 2.4024109840393066\n",
      "Epoch [9/50] Batch 100/938 Loss D: 0.08719699084758759, Loss G: 2.5166897773742676\n",
      "Epoch [9/50] Batch 200/938 Loss D: 0.22570684552192688, Loss G: 3.9065866470336914\n",
      "Epoch [9/50] Batch 300/938 Loss D: 0.04880797117948532, Loss G: 3.0450165271759033\n",
      "Epoch [9/50] Batch 400/938 Loss D: 0.11246257275342941, Loss G: 2.889850378036499\n",
      "Epoch [9/50] Batch 500/938 Loss D: 0.18583953380584717, Loss G: 1.9682140350341797\n",
      "Epoch [9/50] Batch 600/938 Loss D: 0.0875609964132309, Loss G: 2.8135480880737305\n",
      "Epoch [9/50] Batch 700/938 Loss D: 0.04875113442540169, Loss G: 3.330078601837158\n",
      "Epoch [9/50] Batch 800/938 Loss D: 0.18557091057300568, Loss G: 7.234016418457031\n",
      "Epoch [9/50] Batch 900/938 Loss D: 0.10868190973997116, Loss G: 2.5970585346221924\n",
      "Epoch [10/50] Batch 0/938 Loss D: 0.06156322360038757, Loss G: 2.500088691711426\n",
      "Epoch [10/50] Batch 100/938 Loss D: 0.0460970476269722, Loss G: 3.552913188934326\n",
      "Epoch [10/50] Batch 200/938 Loss D: 0.12619754672050476, Loss G: 2.722843647003174\n",
      "Epoch [10/50] Batch 300/938 Loss D: 0.30442070960998535, Loss G: 2.255526542663574\n",
      "Epoch [10/50] Batch 400/938 Loss D: 0.05240444093942642, Loss G: 3.197361469268799\n",
      "Epoch [10/50] Batch 500/938 Loss D: 0.11866801232099533, Loss G: 2.282867431640625\n",
      "Epoch [10/50] Batch 600/938 Loss D: 0.10809893906116486, Loss G: 1.9133654832839966\n",
      "Epoch [10/50] Batch 700/938 Loss D: 0.13858947157859802, Loss G: 3.12211275100708\n",
      "Epoch [10/50] Batch 800/938 Loss D: 0.4953744411468506, Loss G: 2.254225254058838\n",
      "Epoch [10/50] Batch 900/938 Loss D: 0.1062111034989357, Loss G: 2.226630210876465\n",
      "Epoch [11/50] Batch 0/938 Loss D: 0.174705371260643, Loss G: 1.7389369010925293\n",
      "Epoch [11/50] Batch 100/938 Loss D: 0.1678125113248825, Loss G: 2.7046732902526855\n",
      "Epoch [11/50] Batch 200/938 Loss D: 0.14991332590579987, Loss G: 1.7646242380142212\n",
      "Epoch [11/50] Batch 300/938 Loss D: 0.20079964399337769, Loss G: 2.1823205947875977\n",
      "Epoch [11/50] Batch 400/938 Loss D: 0.1500561535358429, Loss G: 3.039668321609497\n",
      "Epoch [11/50] Batch 500/938 Loss D: 0.16013696789741516, Loss G: 1.3793232440948486\n",
      "Epoch [11/50] Batch 600/938 Loss D: 0.16484475135803223, Loss G: 2.3210654258728027\n",
      "Epoch [11/50] Batch 700/938 Loss D: 0.20006099343299866, Loss G: 3.810530662536621\n",
      "Epoch [11/50] Batch 800/938 Loss D: 0.5440624952316284, Loss G: 1.4591403007507324\n",
      "Epoch [11/50] Batch 900/938 Loss D: 0.08008093386888504, Loss G: 2.848886489868164\n",
      "Epoch [12/50] Batch 0/938 Loss D: 0.03818793594837189, Loss G: 2.9413740634918213\n",
      "Epoch [12/50] Batch 100/938 Loss D: 0.25844818353652954, Loss G: 1.5982606410980225\n",
      "Epoch [12/50] Batch 200/938 Loss D: 0.6373314261436462, Loss G: 8.73550796508789\n",
      "Epoch [12/50] Batch 300/938 Loss D: 0.14056262373924255, Loss G: 2.936793565750122\n",
      "Epoch [12/50] Batch 400/938 Loss D: 0.023447874933481216, Loss G: 3.826810359954834\n",
      "Epoch [12/50] Batch 500/938 Loss D: 0.11087889969348907, Loss G: 3.6188740730285645\n",
      "Epoch [12/50] Batch 600/938 Loss D: 0.137664332985878, Loss G: 3.9207890033721924\n",
      "Epoch [12/50] Batch 700/938 Loss D: 0.4834241569042206, Loss G: 13.09496784210205\n",
      "Epoch [12/50] Batch 800/938 Loss D: 0.06385800242424011, Loss G: 3.6324758529663086\n",
      "Epoch [12/50] Batch 900/938 Loss D: 0.04813407361507416, Loss G: 3.2031049728393555\n",
      "Epoch [13/50] Batch 0/938 Loss D: 0.2636997401714325, Loss G: 4.322779178619385\n",
      "Epoch [13/50] Batch 100/938 Loss D: 0.06045070290565491, Loss G: 3.394247531890869\n",
      "Epoch [13/50] Batch 200/938 Loss D: 0.05273476988077164, Loss G: 3.2422752380371094\n",
      "Epoch [13/50] Batch 300/938 Loss D: 0.37575584650039673, Loss G: 0.7183319926261902\n",
      "Epoch [13/50] Batch 400/938 Loss D: 0.04234948009252548, Loss G: 3.2234439849853516\n",
      "Epoch [13/50] Batch 500/938 Loss D: 0.07930532842874527, Loss G: 3.3038315773010254\n",
      "Epoch [13/50] Batch 600/938 Loss D: 0.13660433888435364, Loss G: 2.595554828643799\n",
      "Epoch [13/50] Batch 700/938 Loss D: 0.20100454986095428, Loss G: 3.8059804439544678\n",
      "Epoch [13/50] Batch 800/938 Loss D: 0.6718378663063049, Loss G: 5.802945613861084\n",
      "Epoch [13/50] Batch 900/938 Loss D: 0.0586463138461113, Loss G: 2.5812454223632812\n",
      "Epoch [14/50] Batch 0/938 Loss D: 0.049832284450531006, Loss G: 3.0445363521575928\n",
      "Epoch [14/50] Batch 100/938 Loss D: 0.3153872489929199, Loss G: 2.2200236320495605\n",
      "Epoch [14/50] Batch 200/938 Loss D: 0.24768295884132385, Loss G: 1.0174319744110107\n",
      "Epoch [14/50] Batch 300/938 Loss D: 0.06481386721134186, Loss G: 3.216230630874634\n",
      "Epoch [14/50] Batch 400/938 Loss D: 0.3517662286758423, Loss G: 5.377742767333984\n",
      "Epoch [14/50] Batch 500/938 Loss D: 0.1282253861427307, Loss G: 2.464514970779419\n",
      "Epoch [14/50] Batch 600/938 Loss D: 0.19513244926929474, Loss G: 2.451223850250244\n",
      "Epoch [14/50] Batch 700/938 Loss D: 0.10236586630344391, Loss G: 1.9877525568008423\n",
      "Epoch [14/50] Batch 800/938 Loss D: 0.09105534851551056, Loss G: 3.081883668899536\n",
      "Epoch [14/50] Batch 900/938 Loss D: 0.047644443809986115, Loss G: 3.3065202236175537\n",
      "Epoch [15/50] Batch 0/938 Loss D: 0.07286908477544785, Loss G: 2.583360195159912\n",
      "Epoch [15/50] Batch 100/938 Loss D: 0.1816638708114624, Loss G: 1.97006094455719\n",
      "Epoch [15/50] Batch 200/938 Loss D: 0.1775246411561966, Loss G: 2.5741422176361084\n",
      "Epoch [15/50] Batch 300/938 Loss D: 0.3780643939971924, Loss G: 9.53885269165039\n",
      "Epoch [15/50] Batch 400/938 Loss D: 0.25837209820747375, Loss G: 7.0727858543396\n",
      "Epoch [15/50] Batch 500/938 Loss D: 0.1012738049030304, Loss G: 2.6604151725769043\n",
      "Epoch [15/50] Batch 600/938 Loss D: 2.4649384021759033, Loss G: 29.79167366027832\n",
      "Epoch [15/50] Batch 700/938 Loss D: 0.07706991583108902, Loss G: 3.432523012161255\n",
      "Epoch [15/50] Batch 800/938 Loss D: 0.05865754187107086, Loss G: 2.782562017440796\n",
      "Epoch [15/50] Batch 900/938 Loss D: 0.11219076812267303, Loss G: 4.223938465118408\n",
      "Epoch [16/50] Batch 0/938 Loss D: 0.06571247428655624, Loss G: 3.0127525329589844\n",
      "Epoch [16/50] Batch 100/938 Loss D: 0.07753333449363708, Loss G: 3.8095576763153076\n",
      "Epoch [16/50] Batch 200/938 Loss D: 0.051832735538482666, Loss G: 3.7563846111297607\n",
      "Epoch [16/50] Batch 300/938 Loss D: 0.032847605645656586, Loss G: 3.805717945098877\n",
      "Epoch [16/50] Batch 400/938 Loss D: 0.034447312355041504, Loss G: 4.076136589050293\n",
      "Epoch [16/50] Batch 500/938 Loss D: 0.018520861864089966, Loss G: 5.092458248138428\n",
      "Epoch [16/50] Batch 600/938 Loss D: 0.05164378136396408, Loss G: 8.175106048583984\n",
      "Epoch [16/50] Batch 700/938 Loss D: 0.12822982668876648, Loss G: 2.391573429107666\n",
      "Epoch [16/50] Batch 800/938 Loss D: 0.1479116827249527, Loss G: 4.386093616485596\n",
      "Epoch [16/50] Batch 900/938 Loss D: 0.01499161683022976, Loss G: 3.961965322494507\n",
      "Epoch [17/50] Batch 0/938 Loss D: 0.08802853524684906, Loss G: 4.525945663452148\n",
      "Epoch [17/50] Batch 100/938 Loss D: 0.18308362364768982, Loss G: 2.931138515472412\n",
      "Epoch [17/50] Batch 200/938 Loss D: 0.0666024461388588, Loss G: 3.620337963104248\n",
      "Epoch [17/50] Batch 300/938 Loss D: 0.1801070272922516, Loss G: 1.8695943355560303\n",
      "Epoch [17/50] Batch 400/938 Loss D: 0.04060104116797447, Loss G: 4.169682502746582\n",
      "Epoch [17/50] Batch 500/938 Loss D: 0.004297643434256315, Loss G: 5.433601379394531\n",
      "Epoch [17/50] Batch 600/938 Loss D: 0.001109943026676774, Loss G: 6.141991138458252\n",
      "Epoch [17/50] Batch 700/938 Loss D: 0.24449878931045532, Loss G: 24.505416870117188\n",
      "Epoch [17/50] Batch 800/938 Loss D: 0.005333644803613424, Loss G: 4.630759239196777\n",
      "Epoch [17/50] Batch 900/938 Loss D: 0.011883199214935303, Loss G: 3.858828067779541\n",
      "Epoch [18/50] Batch 0/938 Loss D: 0.08804722130298615, Loss G: 5.720004558563232\n",
      "Epoch [18/50] Batch 100/938 Loss D: 0.15370850265026093, Loss G: 2.464689016342163\n",
      "Epoch [18/50] Batch 200/938 Loss D: 0.05270428583025932, Loss G: 4.761468887329102\n",
      "Epoch [18/50] Batch 300/938 Loss D: 0.02085033431649208, Loss G: 3.9770667552948\n",
      "Epoch [18/50] Batch 400/938 Loss D: 0.015957962721586227, Loss G: 5.63731050491333\n",
      "Epoch [18/50] Batch 500/938 Loss D: 0.01796281337738037, Loss G: 4.4964094161987305\n",
      "Epoch [18/50] Batch 600/938 Loss D: 0.005256722215563059, Loss G: 4.954686164855957\n",
      "Epoch [18/50] Batch 700/938 Loss D: 0.001957257743924856, Loss G: 6.194881439208984\n",
      "Epoch [18/50] Batch 800/938 Loss D: 0.0009690376464277506, Loss G: 6.467198371887207\n",
      "Epoch [18/50] Batch 900/938 Loss D: 0.012152026407420635, Loss G: 4.312631607055664\n",
      "Epoch [19/50] Batch 0/938 Loss D: 0.015144791454076767, Loss G: 4.018063545227051\n",
      "Epoch [19/50] Batch 100/938 Loss D: 0.01880343072116375, Loss G: 5.795402526855469\n",
      "Epoch [19/50] Batch 200/938 Loss D: 0.06842430680990219, Loss G: 4.322940826416016\n",
      "Epoch [19/50] Batch 300/938 Loss D: 0.010680576786398888, Loss G: 4.851395130157471\n",
      "Epoch [19/50] Batch 400/938 Loss D: 0.002863941015675664, Loss G: 5.688289642333984\n",
      "Epoch [19/50] Batch 500/938 Loss D: 0.002864559181034565, Loss G: 5.31063985824585\n",
      "Epoch [19/50] Batch 600/938 Loss D: 0.03276466578245163, Loss G: 6.038689613342285\n",
      "Epoch [19/50] Batch 700/938 Loss D: 0.000595899997279048, Loss G: 6.954488754272461\n",
      "Epoch [19/50] Batch 800/938 Loss D: 0.0014139391714707017, Loss G: 6.353795051574707\n",
      "Epoch [19/50] Batch 900/938 Loss D: 5.355288408281922e-07, Loss G: 38.628089904785156\n",
      "Epoch [20/50] Batch 0/938 Loss D: 0.21457555890083313, Loss G: 17.890846252441406\n",
      "Epoch [20/50] Batch 100/938 Loss D: 0.0026353676803410053, Loss G: 5.626552581787109\n",
      "Epoch [20/50] Batch 200/938 Loss D: 0.008122241124510765, Loss G: 5.997778415679932\n",
      "Epoch [20/50] Batch 300/938 Loss D: 0.004224842879921198, Loss G: 5.900323390960693\n",
      "Epoch [20/50] Batch 400/938 Loss D: 0.018217815086245537, Loss G: 4.226470947265625\n",
      "Epoch [20/50] Batch 500/938 Loss D: 0.0015249216230586171, Loss G: 5.967055797576904\n",
      "Epoch [20/50] Batch 600/938 Loss D: 0.00016914625302888453, Loss G: 8.000754356384277\n",
      "Epoch [20/50] Batch 700/938 Loss D: 0.011285477317869663, Loss G: 6.743480682373047\n",
      "Epoch [20/50] Batch 800/938 Loss D: 0.00466545345261693, Loss G: 4.834399700164795\n",
      "Epoch [20/50] Batch 900/938 Loss D: 0.00034120664349757135, Loss G: 7.316093444824219\n",
      "Epoch [21/50] Batch 0/938 Loss D: 0.00031173258321359754, Loss G: 7.715926170349121\n",
      "Epoch [21/50] Batch 100/938 Loss D: 0.00014936090155970305, Loss G: 8.198935508728027\n",
      "Epoch [21/50] Batch 200/938 Loss D: 0.0002780259819701314, Loss G: 7.554392337799072\n",
      "Epoch [21/50] Batch 300/938 Loss D: 0.0006306963041424751, Loss G: 7.284432888031006\n",
      "Epoch [21/50] Batch 400/938 Loss D: 0.0005390370497480035, Loss G: 6.904574394226074\n",
      "Epoch [21/50] Batch 500/938 Loss D: 0.0016192239709198475, Loss G: 6.860262870788574\n",
      "Epoch [21/50] Batch 600/938 Loss D: 1.1175873559921001e-08, Loss G: 41.860618591308594\n",
      "Epoch [21/50] Batch 700/938 Loss D: 4.181437804522534e-19, Loss G: 41.74414825439453\n",
      "Epoch [21/50] Batch 800/938 Loss D: 4.431407649732996e-19, Loss G: 41.666046142578125\n",
      "Epoch [21/50] Batch 900/938 Loss D: 9.31322685637781e-10, Loss G: 41.017417907714844\n",
      "Epoch [22/50] Batch 0/938 Loss D: 1.862645371275562e-09, Loss G: 41.02468490600586\n",
      "Epoch [22/50] Batch 100/938 Loss D: 2.3104869342205347e-06, Loss G: 40.96921920776367\n",
      "Epoch [22/50] Batch 200/938 Loss D: 2.0489107299681564e-08, Loss G: 40.80841064453125\n",
      "Epoch [22/50] Batch 300/938 Loss D: 9.31322685637781e-10, Loss G: 40.809051513671875\n",
      "Epoch [22/50] Batch 400/938 Loss D: 1.862645371275562e-09, Loss G: 40.79511260986328\n",
      "Epoch [22/50] Batch 500/938 Loss D: 1.4901171851988693e-08, Loss G: 40.451446533203125\n",
      "Epoch [22/50] Batch 600/938 Loss D: 4.656613761255812e-09, Loss G: 40.4383430480957\n",
      "Epoch [22/50] Batch 700/938 Loss D: 1.3969849277373214e-08, Loss G: 40.466514587402344\n",
      "Epoch [22/50] Batch 800/938 Loss D: 3.073369825301597e-08, Loss G: 40.487144470214844\n",
      "Epoch [22/50] Batch 900/938 Loss D: 9.31322685637781e-10, Loss G: 40.14946746826172\n",
      "Epoch [23/50] Batch 0/938 Loss D: 9.31322685637781e-10, Loss G: 40.20854949951172\n",
      "Epoch [23/50] Batch 100/938 Loss D: 1.7695148457619325e-08, Loss G: 40.0952033996582\n",
      "Epoch [23/50] Batch 200/938 Loss D: 1.583249620296101e-08, Loss G: 39.89514923095703\n",
      "Epoch [23/50] Batch 300/938 Loss D: 3.725291186640334e-09, Loss G: 39.88041687011719\n",
      "Epoch [23/50] Batch 400/938 Loss D: 2.4696122388648433e-18, Loss G: 39.96662139892578\n",
      "Epoch [23/50] Batch 500/938 Loss D: 2.9638038512091367e-18, Loss G: 39.78941345214844\n",
      "Epoch [23/50] Batch 600/938 Loss D: 8.381907612431405e-09, Loss G: 39.787052154541016\n",
      "Epoch [23/50] Batch 700/938 Loss D: 3.236347455336171e-18, Loss G: 39.70389175415039\n",
      "Epoch [23/50] Batch 800/938 Loss D: 3.682081173035883e-18, Loss G: 39.584449768066406\n",
      "Epoch [23/50] Batch 900/938 Loss D: 9.31322685637781e-10, Loss G: 39.64520263671875\n",
      "Epoch [24/50] Batch 0/938 Loss D: 1.862645371275562e-09, Loss G: 39.672794342041016\n",
      "Epoch [24/50] Batch 100/938 Loss D: 4.043691863209871e-18, Loss G: 39.50969696044922\n",
      "Epoch [24/50] Batch 200/938 Loss D: 4.240178691554492e-18, Loss G: 39.452274322509766\n",
      "Epoch [24/50] Batch 300/938 Loss D: 4.673737964998648e-18, Loss G: 39.328086853027344\n",
      "Epoch [24/50] Batch 400/938 Loss D: 9.31322685637781e-10, Loss G: 39.42131805419922\n",
      "Epoch [24/50] Batch 500/938 Loss D: 1.862645371275562e-09, Loss G: 39.05361557006836\n",
      "Epoch [24/50] Batch 600/938 Loss D: 6.2638723378527176e-18, Loss G: 39.08988952636719\n",
      "Epoch [24/50] Batch 700/938 Loss D: 2.7939681679356454e-09, Loss G: 38.910919189453125\n",
      "Epoch [24/50] Batch 800/938 Loss D: 6.05361023531259e-08, Loss G: 38.79231262207031\n",
      "Epoch [24/50] Batch 900/938 Loss D: 6.519260686843609e-09, Loss G: 38.44569778442383\n",
      "Epoch [25/50] Batch 0/938 Loss D: 2.477357270436187e-07, Loss G: 38.70060729980469\n",
      "Epoch [25/50] Batch 100/938 Loss D: 3.5390339547802796e-08, Loss G: 38.38794708251953\n",
      "Epoch [25/50] Batch 200/938 Loss D: 4.656614205345022e-09, Loss G: 38.168792724609375\n",
      "Epoch [25/50] Batch 300/938 Loss D: 2.1048174403404118e-07, Loss G: 38.082908630371094\n",
      "Epoch [25/50] Batch 400/938 Loss D: 7.450584149637507e-09, Loss G: 37.9782829284668\n",
      "Epoch [25/50] Batch 500/938 Loss D: 2.2868852291377968e-17, Loss G: 37.72188186645508\n",
      "Epoch [25/50] Batch 600/938 Loss D: 2.3981861855876244e-17, Loss G: 37.631317138671875\n",
      "Epoch [25/50] Batch 700/938 Loss D: 4.656614205345022e-09, Loss G: 37.65028381347656\n",
      "Epoch [25/50] Batch 800/938 Loss D: 2.5143747868409053e-17, Loss G: 37.64714050292969\n",
      "Epoch [25/50] Batch 900/938 Loss D: 2.928379841476553e-17, Loss G: 37.476810455322266\n",
      "Epoch [26/50] Batch 0/938 Loss D: 3.162988115531293e-17, Loss G: 37.35134506225586\n",
      "Epoch [26/50] Batch 100/938 Loss D: 5.190562314237189e-17, Loss G: 36.89805221557617\n",
      "Epoch [26/50] Batch 200/938 Loss D: 3.725291186640334e-09, Loss G: 36.702877044677734\n",
      "Epoch [26/50] Batch 300/938 Loss D: 6.564488797608577e-17, Loss G: 36.624019622802734\n",
      "Epoch [26/50] Batch 400/938 Loss D: 1.3248299391194662e-16, Loss G: 35.92403793334961\n",
      "Epoch [26/50] Batch 500/938 Loss D: 1.862645593320167e-09, Loss G: 35.44473648071289\n",
      "Epoch [26/50] Batch 600/938 Loss D: 5.5879372240497105e-09, Loss G: 34.90718078613281\n",
      "Epoch [26/50] Batch 700/938 Loss D: 7.453668786183698e-06, Loss G: 33.78288650512695\n",
      "Epoch [26/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [26/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [27/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [28/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [29/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [30/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [31/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [32/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [33/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [34/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [35/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [36/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [37/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [38/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [39/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [40/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [41/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [42/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [43/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [44/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [45/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [46/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [47/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [48/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [49/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 0/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 100/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 200/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 300/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 400/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 500/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 600/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 700/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 800/938 Loss D: 50.0, Loss G: 0.0\n",
      "Epoch [50/50] Batch 900/938 Loss D: 50.0, Loss G: 0.0\n",
      "학습 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "epochs = 50\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# 데이터셋 로딩 (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 생성자 네트워크 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img\n",
    "\n",
    "# 판별자 네트워크 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "# 네트워크 초기화\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# 손실 함수와 옵티마이저 설정\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(data_loader):\n",
    "        \n",
    "        # 실제 이미지 라벨: 1, 생성된 이미지 라벨: 0\n",
    "        real_labels = torch.ones((imgs.size(0), 1))\n",
    "        fake_labels = torch.zeros((imgs.size(0), 1))\n",
    "\n",
    "        # 생성자 학습\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn((imgs.size(0), latent_dim))\n",
    "        generated_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 판별자 학습\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(imgs), real_labels)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake_labels)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 중간 결과 출력\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch {i}/{len(data_loader)} Loss D: {d_loss.item()}, Loss G: {g_loss.item()}\")\n",
    "\n",
    "    # 생성된 이미지 확인을 위한 샘플 저장 (매 에포크 끝날 때)\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(64, latent_dim)\n",
    "        generated_imgs = generator(z)\n",
    "        generated_imgs = (generated_imgs + 1) / 2.0  # 이미지를 [0, 1] 범위로 변환\n",
    "        # 이미지 저장 코드는 생략\n",
    "\n",
    "print(\"학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b924da-359d-4c71-ac1c-a67d89f42617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
